---
title: "Observational Studies & Descriptive Statistics"
subtitle: "PSC7475: Week 2"
author: "Prof. Weldzius"
institute: "Villanova University"
date: "Slides Updated: `r Sys.Date()`"
output:
  beamer_presentation:
    theme: "CambridgeUS"
    colortheme: "seahorse"
    fonttheme: "structurebold"
---

```{css,echo = F}
.small .remark-code { /*Change made here*/
  font-size: 85% !important;
}
.tiny .remark-code { /*Change made here*/
  font-size: 50% !important;
}
```

```{r,include=F}
set.seed(123)
options(width=60)
knitr::opts_chunk$set(fig.align='center',fig.width=9,fig.height=5,message=F,warning=F)
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
```

# Do newspaper endorsements matter? 

  * Can newspaper endorsements change voters' minds? \pause 
  * Why not compare vote choice of readers of different papers? \pause 
    - Problem: readers choose papers based on their previous beliefs \pause
    - Liberals $\rightsquigarrow$ New York Times, conservatives $\rightsquigarrow$ Wall Street Journal \pause
  * Could do a lab experiment, but there are concerns over **external validity** \pause
  * Study for today: British newspapers switching their endorsements. \pause
    - Some newspapers endorsing Tories in 1992 switched to Labour in 1997 \pause
    - **Treated group**: readers of Tory $\rightarrow$ Labour papers \pause
    - **Control group**: readers of papers who didn't switch
    
---

# Observational studies

  * Example of an **observational study**: \pause
    - We as researchers observe a naturally assigned treatment \pause
    - Very common: often cna't randomize for ethical/logistical reasons \pause
  * **Internal validity**: Are the causal assumptions satisfied? Can we interpret this as a causal effect? \pause
    - RCTs usually have higher internal validity \pause
    - Observational studies less so, because pre-treatment variable may differ between treatment and control groups \pause
  * **External validity**: Can the conclusions/estimated effects be generalized beyond this study? \pause
    - RCTs weaker here because often very expensive to conduct on representative samples \pause
    - Observational studies often have larger/more representative samples that improve external validity

---    
    
# Confounding

  * **Confounder**: pre-treatment variable affecting treatment and the outcome \pause
    - Leftists ($X$) more likely to read newspapers switching to Labour ($T$) \pause
    - Leftists ($X$) also more likely to vote for Labour ($Y$) \pause
    
  * **Confounding bias** in the estimated SATE due to these differences \pause
    - $\bar{Y}_{control}$ not a good proxy for $Y_i(0)$ in treated group \pause
    - one type: **selection bias** from self-selection into treatment
    
---

# Research designs

  * How can we find a good comparison group? \pause
  * Depends on the data we have available \pause
  * Three general types of observational study **research designs**: \pause
    
    1. **Cross-sectional design**: compare outcomes treated and control units at one point in time \pause
    2. **Before-and-after design**: compare outcomes before and after a unit has been treated, but need over-time data on treated group \pause
    3. **Differences-in-differences design**: use before/after information for the treated and control group; need over-time data on treated and control group
    
---

# Cross-sectional design

  * Compare treatment and control groups after treatment happens \pause
    - Readers of switching papers vs. readers of non-switching papers in 1997 \pause
    
  * Treatment and control groups assumed identical on average as in RCT \pause
    - Sometimes called **unconfoundedness** or **as-if randomized** \pause
    
  * Cross-section comparison estimate: \pause
  
  $$
  \bar{Y}_{treated}^{after} - \bar{Y}_{control}^{after}
  $$
  \pause 
  
  * Could there be confounders?
  
---

# Statistical control

  * **statistical control**: adjust for confounders using statistical procedures  \pause
    - Can help to reduce confounding bias \pause
    
  * One type of statistical control: **subclassification** \pause
    - Compare treated and controls groups within levels of a confounder \pause
    - Remaining effect can't be due to the confounder \pause
    
  * Threat to inference: we can only control for observed variables $\rightsquigarrow$ threat of **unmeasured confounding**
  
---

# Before-and-after comparison

  * Compare readers of party-switching newspapers before and after switch \pause
  * Advantage: all person-specific features held fixed \pause
    - comparing within a person over time \pause
    
  * Before-and-after estimate: \pause
  
  $$
  \bar{Y}_{treated}^{after} - \bar{Y}_{treated}^{before}
  $$
  \pause 
  
  * Threat to inference: **time-varying confounders**
    - Time trend: Labour just did better overall in 1997 compared to 1992
    
---

# Differences in differences (Diff-in-Diff)

  * Key idea: use the before-and-after difference of **control group** to infer what would have happened to **treatment group** without treatment \pause
  * DiD estimate: \pause
  
  $$
  \left(\bar{Y}_{treated}^{after} - \bar{Y}_{treated}^{before} \right) - \left(\bar{Y}_{control}^{after} - \bar{Y}_{control}^{before} \right)
  $$
  \pause 
  
  * Change in treated group above and beyond the change in control group  \pause
  
  * **Parallel time trend assumption** \pause
    - Changes in vote of readers of non-switching papers roughly the same as changes that readers of switching papers would have been if they read non-switching papers \pause
    - Threat to inference: non-parallel trends
    
---

# Summarizing approaches:

  1. **Cross-sectional comparison** 
    - compare treated units with control units after treatment
    - Assumption: treated and control units are comparable
    - Possible confounding \pause
    
  2. **Before-and-after comparison**
    - Compare the same units before and after treatment
    - Assumption: no time-varying confounding \pause
    
  3. **Differences-in-differences**
    - Assumption: parallel trends assumptions
    - Under this assumption, it accounts for unit-specific and time-varying confounding \pause
    
  * All rely on assumptions that can't be verified to handle confounding
  * RCTs handle confounding by design
  
---

# Causality understanding check

\includegraphics[width=1\textwidth]{figs/correlation.png}

See also: https://www.tylervigen.com/spurious-correlations

---

# Lots of data

  * Data from study of the effect of minimum wage
  
```{r, echo=T, results='hide'}
library(tidyverse)
data(minwage, package = "qss")
head(minwage)
```
  
---

# Lots of data

  * Data from study of the effect of minimum wage
  
```{r, echo=F}
library(tidyverse)
data(minwage, package = "qss")
head(minwage)
```
  
---

# Lots and lots of data

  
```{r}
head(minwage$wageAfter, n = 200)
```

---

# How to summarize data

  * How should we summarize the wages data? Many possibilities! \pause
    - Up to now: focus on **averages** or means of variables \pause
    
  * Two salient features of a variable that we want to know: \pause
    - **Central tendency**: where is the middle/typical/average value \pause
    - **Spread** around the center: are all values to the center or spread out?
    
---

# Center of the data

  * "Center" of the data: typical/average value \pause
  * **Mean**: sum of the values divided by the number of observations \pause
  
  $$
  \bar{x} = \frac{1}{n} \sum_{i=1}^{n}{x_i}
  $$
  \pause 
  
  * **Median**: \pause
  
  $$
  \text{median} = 
   \begin{cases}
      \text{middle value} & \text{if number of entries is odd} \\
      \frac{\text{sum of two middle values}}{2} & \text{if number of entries is even}
    \end{cases}  
  $$
  \pause 
  
  * In **R**: `mean()` and `median()` 
  
---

# Mean vs median

  * Median more robust to **outliers**: \pause
    - Example 1: data = ${0,1,2,3,5}$. Mean? Median?
    \vspace{10pt} \pause
    - Example 2: data = ${0,1,2,3,100}$. Mean? Median?
    \vspace{10pt} \pause
  * What does Mark Zuckerberg do to the mean vs. median income?  
  
---

# Spread of the data

  * Are the values of the variable close to the center? \pause
  * **Range**: $[\text{min}(X), \text{max}(X)]$ \pause
  * **Quantile** (quartile, percentile, etc.): divide data into equal sized groups. \pause
    - 25th percentile: lower quartile (25% of the data below this value) \pause
    - 50th percentile: median (50% of the data below this value) \pause
    - 75th percentile: upper quartile (75% of the data below this value) \pause
  * **Interquartile range** (IQR): a measure of variability \pause
    - How spread out is the middle half of the data? \pause
    - Is most of the data really close to the median or are the values spread out? \pause
  * **R** function: `range()`, `summary()`, `IQR()`
  
---

# Standard deviation

  * **Standard deviation**: On average, how far away are data points from the mean? \pause
  
  $$
  \text{standard deviation} = \sqrt{\frac{1}{n-1}\sum_{i=1}^{n}{\left( x_i - \bar{x} \right)^2}}
  $$
  \pause 
  
  * Steps:  \pause
  
    1. Subtract each data point by the mean \pause
    2. Square each resulting difference \pause
    3. Take the sum of these values \pause
    4. Divide by $n-1$ (or $n$, doesn't matter much) \pause
    5. Take the square root \pause
    
  * **Variance**: standard deviation$^2$ \pause
  * Why not just take the average deviations from mean without squaring? 
  
---

# How large is large?

  * Is a wage of 5.30 an hour large? \pause
  * Better question: is 5.30 large relative to the distribution of the data? \pause
    - Big in one dataset might be small in another! \pause
    - Different units, difference spreads of the data, etc. \pause
  * Need a way to put any variable on **common units** \pause
  * **z-score**:  \pause
  
  $$
  \text{z-score of }x_i = \frac{x_i - \text{mean of }x}{\text{standard deviation of }x} 
  $$
  \pause 
  
  * Interpretation: \pause
    - Positive values above the mean, negative values below the mean \pause
    - Units now on the scale of **standard deviations away from the mean** \pause
    - Intuition: data more than 3 SDs away from mean are rare

---

# z-score example

  * Jane works at The Grog where there's a tip jar. \pause
  * She's been keeping track of her daily tips: \pause
    - Average tip of $1.56 with a standard deviation of 20 cents.  \pause
  * Yesterday, Jane got a $1.86 tip. How big is this?
  \vspace{10pt} \pause
  * Today she got $0.56, what about that? 
  
    